{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import nibabel as nib\n",
    "import gdown\n",
    "import imageio\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "from utils.generate_datasets import norm, resize_img, resize_mask, draw_grid, elastic_transform, generate_dataset\n",
    "from utils.generate_models import generate_unet, generate_unet_512\n",
    "from utils.make_predictions import color_mask, create_mask, show_training_predictions, plot_losses\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot using LaTeX, sometimes it gives trouble, in that case comment these two lines\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CPU as the only available physical device, as my GPU memory is not enough sometimes\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are provided by [COVID-19 CT segmentation dataset\n",
    "](http://medicalsegmentation.com/covid19/), it is a dataset of 100 axial CT images from more than 40 patients with COVID-19. The images were segmented by a radiologist using 3 labels: \n",
    "\n",
    "- Ground-glass (mask value = 1)\n",
    "- Consolidation (mask value = 2)\n",
    "- Pleural effusion (mask value = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir images\n",
    "! mkdir gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training images \n",
    "gdown.download('https://drive.google.com/uc?id=1nYbe37SmMIwBQJ35MR3coDEKqaMeuiCu',\n",
    "               output='images/tr_im.nii', quiet=True)\n",
    "\n",
    "# Training masks\n",
    "gdown.download('https://drive.google.com/uc?id=16Wdd97TAI3IBFTaQ7yth1qSo7wsEcZCc',\n",
    "               output='images/tr_mask.nii', quiet=True)\n",
    "\n",
    "# Validation dataset\n",
    "gdown.download('https://drive.google.com/uc?id=1xNVxrnIlO96ydXy5b6rLLuAvgbFT2Tz0',\n",
    "               output='images/val_im.nii', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = nib.load('images/tr_im.nii')\n",
    "masks = nib.load('images/tr_mask.nii')\n",
    "validation = nib.load('images/val_im.nii')\n",
    "\n",
    "x_o = imgs.get_fdata()\n",
    "y_o = masks.get_fdata()\n",
    "\n",
    "x_o = np.array([norm(resize_img(x_o[:,:,i], 512)) for i in range(imgs.shape[2])])\n",
    "y_o = np.array([resize_mask(y_o[:,:,i], 512) for i in range(imgs.shape[2])])\n",
    "\n",
    "x_o.shape, y_o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating datasets and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        clear_output(wait=True)\n",
    "        show_training_predictions(self.model, x_val, y_val, size, epoch, logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512 $\\times$ 512 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_512 = generate_unet_512()\n",
    "model_512.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "samples = 4000\n",
    "size = 512\n",
    "\n",
    "TRAIN_LENGTH = samples\n",
    "BATCH_SIZE = 100\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_512 = ModelCheckpoint(\"models/best_weights_512.h5\", \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True, \n",
    "                                 mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 512$\\times$512 dataset is quite heavy (for my computer), so it is better to divide it in *batches*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 10\n",
    "imgs_per_batch = int(imgs.shape[2] / batches)\n",
    "samples_per_batch = int(samples / batches)\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for i in range(batches):\n",
    "    print(\"Generating augmented 512x512 dataset of size {}\".format(samples_per_batch))\n",
    "    x_val, y_val, x, y = generate_dataset(\n",
    "                       imgs.slicer[:, :, imgs_per_batch*i:imgs_per_batch*(i+1)], \n",
    "                       masks.slicer[:, :, imgs_per_batch*i:imgs_per_batch*(i+1)], \n",
    "                       size, samples_per_batch)\n",
    "    \n",
    "    print(\"Training 512x512 (step {})\".format(i+1))\n",
    "    trained_512 = model_512.fit(x, y, validation_data=(x_val, y_val),\n",
    "                            epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                            callbacks=[checkpoint_512, DisplayCallback()])\n",
    "    \n",
    "    losses.append(trained_512.history['loss'])\n",
    "    val_losses.append(trained_512.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(losses[0], val_losses[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model_512.to_json()\n",
    "with open('models/model_512.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model_512.save_weights('models/model_512.h5')\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 224 $\\times$ 224 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_224 = generate_unet(224)\n",
    "model_224.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "samples = 4000\n",
    "size = 224\n",
    "\n",
    "TRAIN_LENGTH = samples\n",
    "BATCH_SIZE = 100\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_224 = ModelCheckpoint(\"models/best_weights_224.h5\", \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True, \n",
    "                                 mode='min')\n",
    "\n",
    "print(\"Generating augmented 224x224 dataset of size {}\".format(samples))\n",
    "x_val, y_val, x, y = generate_dataset(imgs, masks, size, samples)\n",
    "\n",
    "print(\"Training 224x224\")\n",
    "trained_224 = model_224.fit(x, y, validation_data=(x_val, y_val),\n",
    "                            epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                            callbacks = [checkpoint_224, DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(trained_224.history['loss'], trained_224.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model_224.to_json()\n",
    "with open('models/model_224.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_224.save_weights('models/model_224.h5')\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 192 $\\times$ 192 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_192 = generate_unet(192)\n",
    "model_192.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "samples = 4000\n",
    "size = 192\n",
    "\n",
    "TRAIN_LENGTH = samples\n",
    "BATCH_SIZE = 100\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_192 = ModelCheckpoint(\"models/best_weights_192.h5\", \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True, \n",
    "                                 mode='min')\n",
    "\n",
    "print(\"Generating augmented 192x192 dataset of size {}\".format(samples))\n",
    "x_val, y_val, x, y = generate_dataset(imgs, masks, size, samples)\n",
    "\n",
    "print(\"Training 192x192\")\n",
    "trained_192 = model_192.fit(x, y, validation_data=(x_val, y_val),\n",
    "                            epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                            callbacks = [checkpoint_192, DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(trained_192.history['loss'], trained_192.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model_192.to_json()\n",
    "with open('models/model_192.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_192.save_weights('models/model_192.h5')\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GIF\n",
    "\n",
    "Create a simple animation of the training process for one of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "filenames = ['gif/192_{}.jpg'.format(i) for i in range(EPOCHS)]\n",
    "\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "    \n",
    "imageio.mimsave('gif/training_192.gif', images, duration=0.4, loop=0, fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
